# -*- coding: utf-8 -*-
"""diabetes.data

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dvflKABtB79U8XT1HAltCfMSP6DkBvYu
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.naive_bayes import BernoulliNB
from sklearn.svm import LinearSVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.preprocessing import LabelBinarizer

from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, f1_score, recall_score, roc_curve, roc_auc_score

"""Reading the dataset"""

dataset = pd.read_csv('/content/diabetes_data.csv',delimiter=";")
dataset.head()

dataset.isnull().sum()

dataset.info()

"""Showing the informations"""

fig = px.histogram(dataset, x = 'Age', color = 'Level', nbins = 10, title = 'Distribution of ages', text_auto = True)
fig.show()

fig = px.box(dataset, x = 'Age', y = 'Level')
fig.show()

def graph(x, y, title):
  fig = px.histogram(dataset, x = x, y = y, color = 'Level', barmode = 'group',
                   title = title, text_auto = True)
  fig.show()

  fig = px.box(dataset, x = x, y = 'Level')
  fig.show()

graph('Alcohol use', 'Gender', 'Distribution of Alcohol use')

graph('Dust Allergy', 'Gender', 'Distribution of Dust Allergy')

graph('OccuPational Hazards', 'Gender', 'Distribution of OccuPational Hazards')

graph('Genetic Risk', 'Gender', 'Distribution of Genetic Risk')

graph('chronic Lung Disease', 'Gender', 'Distribution of Chronic Lung Disease')

graph('Balanced Diet', 'Gender', 'Distribution of Balanced Diet')

graph('Obesity', 'Gender', 'Distribution of Obesity')

graph('Smoking', 'Gender', 'Distribution of Smoking')

graph('Passive Smoker', 'Gender', 'Distribution of Passive Smoker')

graph('Chest Pain', 'Gender', 'Distribution of Chest Pain')

graph('Coughing of Blood', 'Gender', 'Distribution of Coughing of Blood')

graph('Fatigue', 'Gender', 'Distribution of Fatigue')

graph('Weight Loss', 'Gender', 'Distribution of Weight Loss')

graph('Shortness of Breath', 'Gender', 'Distribution of Shortness of Breath')

graph('Wheezing', 'Gender', 'Distribution of Wheezing')

graph('Swallowing Difficulty', 'Gender', 'Distribution of Swallowing Difficulty')

graph('Clubbing of Finger Nails', 'Gender', 'Distribution of Clubbing of Finger Nails')

graph('Frequent Cold', 'Gender', 'Distribution of Frequent Cold')

graph('Dry Cough', 'Gender', 'Distribution of Dry Cough')

graph('Snoring', 'Gender', 'Distribution of Snoring')

fig = px.histogram(dataset, x = 'Level', y = 'Gender', color = 'Gender', barmode = 'group',
                   title = 'Distribution of Level', text_auto = True)
fig.show()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# dataset.hist(bins=30, figsize=(18,12))
# plt.show()

"""What the data shows for us?
It's possible to understand that according the level of column is increasing, higher is the level of people risk. There are few examples where exist some outliers. Perhaps, the medium risk isn't so objective, because it's the average between high and low values, and it isn't such a clear category to define specifically.



"""

dataset.describe()

"""Standarding the data"""

dataset['gender'].replace(to_replace=["Male", "Female"], value = [0,1], inplace = True)

dataset= dataset()

standard = StandardScaler()
dataset_standard = standard.fit_transform(dataset)

dataset_standard_2 = pd.DataFrame(data = dataset_standard, columns = dataset.keys())

correlation = dataset_standard_2.corr()
graph = sns.heatmap(correlation, annot = True, fmt = '.2f')
graph.figure.set_size_inches(24, 16)
graph.set_title('Correlation Matriz', fontsize = 30)

"""Separating the data between train and test"""

age_boundaries = [0, 18, 30, 40, 60, 70, 100]

labels = ['0-18', '19-30', '30-40', '41-60', '61-70', '>70']

# create age_cat variable
dataset['age_cat'] = pd.cut(
    dataset['age'], bins=age_boundaries, labels=labels, include_lowest=True)

dataset.head(2)

X = dataset.iloc[:, :-1]
y = dataset.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

X_train.shape, X_test.shape

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""Running the models"""

from sklearn.metrics import confusion_matrix

bnb = BernoulliNB()
bnb.fit(X_train, y_train)
bnb_predict = bnb.predict(X_test)

accuracy_bnb = accuracy_score(y_test, bnb_predict)

confusion_matrix = confusion_matrix(y_test, bnb_predict)
plt.figure(figsize = (6,6))
sns.set(font_scale = 1)
sns.heatmap(confusion_matrix, annot = True, fmt = '.1f').set(xlabel = 'Prediction', ylabel = 'Real')

print('Accuracy: {:.2f}'.format(accuracy_bnb))

print(bnb_predict.shape)

X_test

y_test

print(dtc.predict(X_test))

from sklearn.metrics import confusion_matrix

svc = LinearSVC()
svc.fit(X_train, y_train)
svc_predict = svc.predict(X_test)

accuracy_svc = accuracy_score(y_test, svc_predict)

confusion_matrix = confusion_matrix(y_test, svc_predict)
plt.figure(figsize = (6,6))
sns.set(font_scale = 1)
sns.heatmap(confusion_matrix, annot = True, fmt = '.1f').set(xlabel = 'Prediction', ylabel = 'Real')

print('Accuracy: {:.2f}'.format(accuracy_svc))

from sklearn.metrics import confusion_matrix

knn = KNeighborsClassifier(metric='euclidean')
knn.fit(X_train, y_train)
knn_predict = knn.predict(X_test)

accuracy_knn = accuracy_score(y_test, knn_predict)

confusion_matrix = confusion_matrix(y_test, knn_predict)
plt.figure(figsize = (6,6))
sns.set(font_scale = 1)
sns.heatmap(confusion_matrix, annot = True, fmt = '.1f').set(xlabel = 'Prediction', ylabel = 'Real')

print('Accuracy: {:.2f}'.format(accuracy_knn))

knn_predict.shape

from sklearn.metrics import confusion_matrix

dtc = DecisionTreeClassifier(criterion='entropy', random_state = 40)
dtc.fit(X_train, y_train)
dtc_predict = dtc.predict(X_test)

accuracy_dtc = accuracy_score(y_test, dtc_predict)

confusion_matrix = confusion_matrix(y_test, dtc_predict)
plt.figure(figsize = (6,6))
sns.set(font_scale = 1)
sns.heatmap(confusion_matrix, annot = True, fmt = '.1f').set(xlabel = 'Prediction', ylabel = 'Real')

print('Accuracy: {:.2f}'.format(accuracy_dtc))

from sklearn.metrics import confusion_matrix

rfc = RandomForestClassifier(n_estimators = 100)
rfc.fit(X_train, y_train)
rfc_predict = rfc.predict(X_test)

accuracy_rfc = accuracy_score(y_test, rfc_predict)

confusion_matrix = confusion_matrix(y_test, rfc_predict)
plt.figure(figsize = (6,6))
sns.set(font_scale = 1)
sns.heatmap(confusion_matrix, annot = True, fmt = '.1f').set(xlabel = 'Prediction', ylabel = 'Real')

print('Accuracy: {:.2f}'.format(accuracy_rfc))

"""Calculating the ROC curve of each model"""

lb = LabelBinarizer()
y_test = lb.fit_transform(y_test)
bnb_predict = lb.fit_transform(bnb_predict)
svc_predict = lb.fit_transform(svc_predict)
knn_predict = lb.fit_transform(knn_predict)
dtc_predict = lb.fit_transform(dtc_predict)
rfc_predict = lb.fit_transform(rfc_predict)

bnb_auc = [0] * 3
bnb_fpr = [0] * 3
bnb_tpr = [0] * 3
bnb_thresholds = [0] * 3

svc_auc = [0] * 3
svc_fpr = [0] * 3
svc_tpr = [0] * 3
svc_thresholds = [0] * 3

knn_auc = [0] * 3
knn_fpr = [0] * 3
knn_tpr = [0] * 3
knn_thresholds = [0] * 3

dtc_auc = [0] * 3
dtc_fpr = [0] * 3
dtc_tpr = [0] * 3
dtc_thresholds = [0] * 3

rfc_auc = [0] * 3
rfc_fpr = [0] * 3
rfc_tpr = [0] * 3
rfc_thresholds = [0] * 3

for i in range(len(bnb_auc)):
  bnb_auc[i] = roc_auc_score(y_test[:, i], bnb_predict[:, i], multi_class = 'ovr', average = 'macro')
  svc_auc[i] = roc_auc_score(y_test[:, i], svc_predict[:, i], multi_class = 'ovr', average = 'macro')
  knn_auc[i] = roc_auc_score(y_test[:, i], knn_predict[:, i], multi_class = 'ovr', average = 'macro')
  dtc_auc[i] = roc_auc_score(y_test[:, i], dtc_predict[:, i], multi_class = 'ovr', average = 'macro')
  rfc_auc[i] = roc_auc_score(y_test[:, i], rfc_predict[:, i], multi_class = 'ovr', average = 'macro')
  bnb_fpr[i], bnb_tpr[i], bnb_thresholds[i] = roc_curve(y_test[:, i], bnb_predict[:, i])
  svc_fpr[i], svc_tpr[i], svc_thresholds[i] = roc_curve(y_test[:, i], svc_predict[:, i])
  knn_fpr[i], knn_tpr[i], knn_thresholds[i] = roc_curve(y_test[:, i], knn_predict[:, i])
  dtc_fpr[i], dtc_tpr[i], dtc_thresholds[i] = roc_curve(y_test[:, i], dtc_predict[:, i])
  rfc_fpr[i], rfc_tpr[i], rfc_thresholds[i] = roc_curve(y_test[:, i], rfc_predict[:, i])

plt.figure(figsize = (7, 7))
plt.plot(bnb_fpr[0], bnb_tpr[0], label = 'Naive Bayes Model (Low) - ROC Curve (area = %.2f)' %bnb_auc[0])
plt.plot(bnb_fpr[1], bnb_tpr[1], label = 'Naive Bayes Model (Medium) - ROC Curve (area = %.2f)' %bnb_auc[1])
plt.plot(bnb_fpr[2], bnb_tpr[2], label = 'Naive Bayes Model (High) - ROC Curve (area = %.2f)' %bnb_auc[2])
plt.plot([0, 1], [0, 1], linestyle = '--', color = 'r', label = 'Random guess')
plt.title('ROC curve (Naive Bayes)')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.grid(True)
plt.legend()
plt.show()

plt.figure(figsize = (7, 7))
plt.plot(svc_fpr[0], svc_tpr[0], label = 'Linear SVC Model (Low) - ROC Curve (area = %.2f)' %svc_auc[0])
plt.plot(svc_fpr[1], svc_tpr[1], label = 'Linear SVC Model (Medium) - ROC Curve (area = %.2f)' %svc_auc[1])
plt.plot(svc_fpr[2], svc_tpr[2], label = 'Linear SVC Model (High) - ROC Curve (area = %.2f)' %svc_auc[2])
plt.plot([0, 1], [0, 1], linestyle = '--', color = 'r', label = 'Random guess')
plt.title('ROC curve (Linear SVC)')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.grid(True)
plt.legend()
plt.show()

plt.figure(figsize = (7, 7))
plt.plot(knn_fpr[0], knn_tpr[0], label = 'KNN Model (Low) - ROC Curve (area = %.2f)' %knn_auc[0])
plt.plot(knn_fpr[1], knn_tpr[1], label = 'KNN Model (Medium) - ROC Curve (area = %.2f)' %knn_auc[1])
plt.plot(knn_fpr[2], knn_tpr[2], label = 'KNN Model (High) - ROC Curve (area = %.2f)' %knn_auc[2])
plt.plot([0, 1], [0, 1], linestyle = '--', color = 'r', label = 'Random guess')
plt.title('ROC curve (KNN)')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.grid(True)
plt.legend()
plt.show()

plt.figure(figsize = (7, 7))
plt.plot(dtc_fpr[0], dtc_tpr[0], label = 'Dec. Tree Class. Model (Low) - ROC Curve (area = %.2f)' %dtc_auc[0])
plt.plot(dtc_fpr[1], dtc_tpr[1], label = 'Dec. Tree Class. Model (Medium) - ROC Curve (area = %.2f)' %dtc_auc[1])
plt.plot(dtc_fpr[2], dtc_tpr[2], label = 'Dec. Tree Class. Model (High) - ROC Curve (area = %.2f)' %dtc_auc[2])
plt.plot([0, 1], [0, 1], linestyle = '--', color = 'r', label = 'Random guess')
plt.title('ROC curve (Decision Tree Classifier)')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.grid(True)
plt.legend()
plt.show()

plt.figure(figsize = (7, 7))
plt.plot(rfc_fpr[0], rfc_tpr[0], label = 'Random Forest Class. Model (Low) - ROC Curve (area = %.2f)' %rfc_auc[0])
plt.plot(rfc_fpr[1], rfc_tpr[1], label = 'Random Forest Class. Model (Medium) - ROC Curve (area = %.2f)' %rfc_auc[1])
plt.plot(rfc_fpr[2], rfc_tpr[2], label = 'Random Forest Class. Model (High) - ROC Curve (area = %.2f)' %rfc_auc[2])
plt.plot([0, 1], [0, 1], linestyle = '--', color = 'r', label = 'Random guess')
plt.title('ROC curve (Random Forest Classifier)')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.grid(True)
plt.legend()
plt.show()

"""Conclusion

Except the Naive Bayes, the rest of models have satisfied number of accuracy. However, the test data was small (250) to be sure that these models will be right every time when it insert new informations to predict. It'll be necessary a bigger dataset to train more and to analysis if the accuracy'll be the same or it will be decrease.

Logistic Regression and Decision Tree Performs Better
"""

